{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QRGBdFdE-68m"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "QRGBdFdE-68m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZRavP6C1Cbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f649fe6-3cf2-4038-9d98-ffc351cd7114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m780.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain langchain-community langchain_openai google-search-results html2text --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ikO63Za8DlTu",
        "outputId": "8148fb77-99cc-4fed-ab04-8e9ca3238b6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My Drive/5CHackathon/"
      ],
      "metadata": {
        "id": "95ui7n4ZDmIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e5488d-66cd-47ff-a73d-e833e4d79a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/5CHackathon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4j1EoQxD7vV",
        "outputId": "1315819f-4de0-4248-f89a-cc316883f147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## secret keys\n",
        "\n",
        "import os\n",
        "os.environ[\"SERP_API_KEY\"] = \"9feadd7de85fe63dcd0d8ab007ee50cce9b3e88a5c65a10ce295c79ff05541b9\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "fFY0T9N-QR0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "LmitHHfd-9JN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# general imports\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import html2text\n",
        "\n",
        "# google scholar\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "# langchain\n",
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "from langchain_community.document_loaders import AsyncHtmlLoader\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "9DDQyH9B_W3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_llm(provider=\"openai\", max_tokens=100, temperature=0.5):\n",
        "    \"\"\"\n",
        "    Load the language model from the specified provider.\n",
        "    Openai loads gpt-3.5-turbo by default.\n",
        "    Huggingface can be added later.\n",
        "\n",
        "    input:\n",
        "        provider: str, \"openai\" or \"huggingface\"\n",
        "        max_tokens: int, maximum number of tokens to generate\n",
        "        temperature: float, temperature for sampling\n",
        "    output:\n",
        "        llm: Langchain language model object\n",
        "    \"\"\"\n",
        "\n",
        "    if provider == \"openai\":\n",
        "        llm = ChatOpenAI(\n",
        "            model=\"gpt-3.5-turbo\", max_tokens=max_tokens, temperature=temperature\n",
        "        )\n",
        "\n",
        "    # elif provider == \"huggingface\":\n",
        "    # Load the model from Hugging Face\n",
        "\n",
        "    return llm\n",
        "\n",
        "\n",
        "# Class to search google scholar\n",
        "## query function for searching papers\n",
        "## user function for searching authors\n",
        "## returns JSON objects\n",
        "class SearchScholar:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def query(self, query, as_ylo=2018, as_yhi=2024, start=0, num=10):\n",
        "        params = {\n",
        "            \"engine\": \"google_scholar\",\n",
        "            \"api_key\": os.getenv(\"SERP_API_KEY\"),\n",
        "            \"q\": query,\n",
        "            \"as_ylo\": as_ylo,\n",
        "            \"as_yhi\": as_yhi,\n",
        "            \"hl\": \"en\",\n",
        "            \"start\": start,\n",
        "            \"num\": num,  # limited to 20\n",
        "            \"output\": \"json\",\n",
        "        }\n",
        "\n",
        "        search = GoogleSearch(params)\n",
        "        results = search.get_dict()\n",
        "        organic_results = results.get(\"organic_results\", [])\n",
        "\n",
        "        return results, organic_results\n",
        "\n",
        "    def author_profiles(self, authors_info):\n",
        "        for author in authors_info[:2]:\n",
        "            params = {\n",
        "                \"engine\": \"google_scholar_author\",\n",
        "                \"api_key\": os.getenv(\"SERP_API_KEY\"),\n",
        "                \"author_id\": author[\"author_id\"],\n",
        "                \"output\": \"json\",\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                search = GoogleSearch(params)\n",
        "                results = search.get_dict()\n",
        "                author_data = results.get(\"author\", {})\n",
        "                author[\"affiliations\"] = author_data.get(\n",
        "                    \"affiliations\", \"No Affiliation Found\"\n",
        "                )\n",
        "                # Extracting interests (could be multiple)\n",
        "                interests = author_data.get(\"interests\", [])\n",
        "                author[\"interests\"] = [interest[\"title\"] for interest in interests]\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to fetch information for author {author['name']}: {e}\")\n",
        "                author[\"affiliations\"] = \"No profile found\"\n",
        "\n",
        "        return authors_info\n",
        "\n",
        "\n",
        "# Class to parse JSON combining the functions below\n",
        "## parse entire JSON to authors json\n",
        "## parse authors json to list\n",
        "class JSONParser:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # Function to get author information from the JSON data\n",
        "    ## will still return json, but just of the authors\n",
        "    def extract_authors(self, json_data):\n",
        "        authors_info = []\n",
        "\n",
        "        # Iterate through each paper\n",
        "        for entry in json_data:\n",
        "            publication_info = entry.get(\"publication_info\", {})\n",
        "            authors = publication_info.get(\"authors\", [])\n",
        "\n",
        "            # Iterate through each author in the paper\n",
        "            for author in authors:\n",
        "                # Desired information to extract\n",
        "                author_details = {\n",
        "                    \"name\": author.get(\"name\", \"No Name Provided\"),\n",
        "                    \"link\": author.get(\"link\", \"No Link Provided\"),\n",
        "                    \"serpapi_scholar_link\": author.get(\n",
        "                        \"serpapi_scholar_link\", \"No SerpApi Link Provided\"\n",
        "                    ),\n",
        "                    \"author_id\": author.get(\"author_id\", \"No Author ID Provided\"),\n",
        "                }\n",
        "                # Add author info\n",
        "                authors_info.append(author_details)\n",
        "\n",
        "        return authors_info\n",
        "\n",
        "    # Function to parse authors' information from the JSON data\n",
        "    ## should add a string description for each author that can be displayed in the dropdown menu\n",
        "    def author_string(self, authors_info):\n",
        "        # Iterate through authors to add a 'parsed_string' trait\n",
        "        for author in authors_info:\n",
        "            formatted_str = f\"{author['name']} --- {author.get('affiliations', 'No Affiliation Found')}\"\n",
        "            author[\"parsed_string\"] = formatted_str\n",
        "\n",
        "        return authors_info\n",
        "\n",
        "\n",
        "# Function to fetch university admissions data from the database\n",
        "## should take in the institution chosen by the user and return the university admissions data\n",
        "def load_admissions_data():\n",
        "    # Load the admissions data from the database\n",
        "    admissions_data = pd.read_csv(\"data/Merged_Admissions_Data.csv\")\n",
        "\n",
        "    return admissions_data\n",
        "\n",
        "\n",
        "def extract_state_universities(institution):\n",
        "    llm = load_llm(max_tokens=2, temperature=0.5)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "            The following string contains the name of an accredited university.\n",
        "\n",
        "            {institution}\n",
        "\n",
        "            You must return the two-letter abbreviation of the state where the university is located (i.e., Washington = WA, or Virginia = VA).\n",
        "\n",
        "            STABBR:\n",
        "        \"\"\"\n",
        "\n",
        "    state = llm.invoke(prompt)\n",
        "\n",
        "    return state.content\n",
        "\n",
        "\n",
        "def fetch_admissions_state_data(institution):\n",
        "    # Load the admissions data\n",
        "    admissions_data = load_admissions_data()\n",
        "\n",
        "    state = extract_state_universities(institution)\n",
        "    print(\"The extracted state is:\", repr(state))\n",
        "\n",
        "    # Determine which list to use based on the existence of the state\n",
        "    if state in admissions_data[\"STABBR\"].values:\n",
        "        institutions_list = admissions_data[admissions_data[\"STABBR\"] == state][\n",
        "            \"INSTNM\"\n",
        "        ].tolist()\n",
        "\n",
        "        # Find top 3 similarity\n",
        "        top3_universities = find_university(institutions_list, institution)\n",
        "\n",
        "        # Build dataframe for top 3 universities\n",
        "        universities_data = pd.DataFrame()\n",
        "        for university in top3_universities:\n",
        "            university_data = get_university_data(university)\n",
        "            universities_data = pd.concat([universities_data, university_data])\n",
        "    else:\n",
        "        print(\n",
        "            \"WARNING: We currently don't support international universities. We are unable to fetch statistics at this time.\"\n",
        "        )\n",
        "        universities_data = None\n",
        "\n",
        "    return universities_data, institution\n",
        "\n",
        "\n",
        "\n",
        "def find_university(state_data, author_institution):\n",
        "    \"\"\"\n",
        "    Takes in the list of universities in a state and returns the university with the highest cosine similarity with the author's institution.\n",
        "    inputs:\n",
        "        state_data: list of universities in a state\n",
        "        author_institution: institution of the author\n",
        "    outputs:\n",
        "        university: the university with the highest cosine similarity with the author's institution\n",
        "    \"\"\"\n",
        "\n",
        "    # Creating the TF-IDF Vectorizer\n",
        "    vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Including the author's institution in the list for vectorization\n",
        "    all_text = state_data + [author_institution]\n",
        "\n",
        "    # Transforming the text to TF-IDF vectors\n",
        "    tfidf_matrix = vectorizer.fit_transform(all_text)\n",
        "\n",
        "    # Calculating cosine similarity between the author's institution and all universities in the state\n",
        "    # The last entry in tfidf_matrix is the author's institution\n",
        "    cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
        "\n",
        "    # get the indices for the top three cosine similarities\n",
        "    top_indices = cosine_similarities.argsort()[0][::-1][:3]\n",
        "\n",
        "    # filter state data to get the top three universities\n",
        "    top_universities = [state_data[i] for i in top_indices]\n",
        "\n",
        "    # Returning the university with the highest cosine similarity\n",
        "    return top_universities\n",
        "\n",
        "\n",
        "def get_university_data(university):\n",
        "    # Load the admissions data\n",
        "    admissions_data = load_admissions_data()\n",
        "\n",
        "    # Filter the data based on the selected institution\n",
        "    try:\n",
        "        university_data = admissions_data[admissions_data[\"INSTNM\"] == university]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"We couldn't fetch your school: {e}\")\n",
        "\n",
        "    return university_data\n"
      ],
      "metadata": {
        "id": "oa8voKSG_LYN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "_jZKkviW_IZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "import re\n",
        "import json"
      ],
      "metadata": {
        "id": "NBLd1mxb_6Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_institution_data():\n",
        "\n",
        "    university = st.text_input(\"Enter the name of the institution to fetch the data:\")\n",
        "\n",
        "    if st.button(\"Get univesity admissions data\"):\n",
        "        with st.spinner(\"Fetching data...\"):\n",
        "\n",
        "            uni_data = get_university_data(university)\n",
        "            st.dataframe(uni_data)"
      ],
      "metadata": {
        "id": "oT-554SiAiIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get user's input (research interests)\n",
        "user_input = \"computer science\"\n",
        "\n",
        "# Instantiate the classes in the beginning\n",
        "search_scholar = SearchScholar()\n",
        "json_parser = JSONParser()\n",
        "\n",
        "if len(user_input) > 5:\n",
        "\n",
        "    # user user input to fetch google scholar papers\n",
        "    results, organic_results = search_scholar.query(user_input)\n",
        "\n",
        "    # get author's info from papers\n",
        "    authors_info = json_parser.extract_authors(organic_results)\n",
        "\n",
        "    # add info from google scholar profiles\n",
        "    authors_info = search_scholar.author_profiles(authors_info)\n",
        "\n",
        "    # get authors' institutions and research interests\n",
        "    authors_info = json_parser.author_string(\n",
        "        authors_info\n",
        "    )  # adds pairs of author-insitution"
      ],
      "metadata": {
        "id": "lAPk7DOD_1Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(authors_info, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddpzls9WCDvX",
        "outputId": "b4d54c75-db89-4259-c1cd-01233b7d1ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"name\": \"Y Qian\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=XC6uLJMAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=XC6uLJMAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"XC6uLJMAAAAJ\",\n",
            "        \"affiliations\": \"Jiangnan University\",\n",
            "        \"interests\": [\n",
            "            \"Computer Science Education\",\n",
            "            \"Computing Education\",\n",
            "            \"STEM Education\",\n",
            "            \"Novice Programming\"\n",
            "        ],\n",
            "        \"parsed_string\": \"Y Qian --- Jiangnan University\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"S Hambrusch\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=5k0KS3UAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=5k0KS3UAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"5k0KS3UAAAAJ\",\n",
            "        \"affiliations\": \"Professor, Purdue University\",\n",
            "        \"interests\": [\n",
            "            \"Computer science education\",\n",
            "            \"Algorithms\"\n",
            "        ],\n",
            "        \"parsed_string\": \"S Hambrusch --- Professor, Purdue University\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"A Yadav\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=E_kmtUQAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=E_kmtUQAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"E_kmtUQAAAAJ\",\n",
            "        \"parsed_string\": \"A Yadav --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"T Crick\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=4imYGSEAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=4imYGSEAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"4imYGSEAAAAJ\",\n",
            "        \"parsed_string\": \"T Crick --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"C Knight\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=0M7wN6EAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=0M7wN6EAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"0M7wN6EAAAAJ\",\n",
            "        \"parsed_string\": \"C Knight --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"R Watermeyer\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=GBo_LxcAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=GBo_LxcAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"GBo_LxcAAAAJ\",\n",
            "        \"parsed_string\": \"R Watermeyer --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"B Efron\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=duBlF_YAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=duBlF_YAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"duBlF_YAAAAJ\",\n",
            "        \"parsed_string\": \"B Efron --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"T Hastie\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=tQVe-fAAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=tQVe-fAAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"tQVe-fAAAAAJ\",\n",
            "        \"parsed_string\": \"T Hastie --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"MV M\\u00e4ntyl\\u00e4\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=iD0POWUAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=iD0POWUAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"iD0POWUAAAAJ\",\n",
            "        \"parsed_string\": \"MV M\\u00e4ntyl\\u00e4 --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"D Graziotin\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=HSIXSFIAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=HSIXSFIAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"HSIXSFIAAAAJ\",\n",
            "        \"parsed_string\": \"D Graziotin --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"M Kuutila\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=bLG5nKYAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=bLG5nKYAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"bLG5nKYAAAAJ\",\n",
            "        \"parsed_string\": \"M Kuutila --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"R Szeliski\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=3_u1jHQAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=3_u1jHQAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"3_u1jHQAAAAJ\",\n",
            "        \"parsed_string\": \"R Szeliski --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"A Klimova\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=Nn5s33cAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=Nn5s33cAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"Nn5s33cAAAAJ\",\n",
            "        \"parsed_string\": \"A Klimova --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"WF Aspray\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=5JYqVY8AAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=5JYqVY8AAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"5JYqVY8AAAAJ\",\n",
            "        \"parsed_string\": \"WF Aspray --- No Affiliation Found\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"JR Yost\",\n",
            "        \"link\": \"https://scholar.google.com/citations?user=TJtm2_UAAAAJ&hl=en&oi=sra\",\n",
            "        \"serpapi_scholar_link\": \"https://serpapi.com/search.json?author_id=TJtm2_UAAAAJ&engine=google_scholar_author&hl=en\",\n",
            "        \"author_id\": \"TJtm2_UAAAAJ\",\n",
            "        \"parsed_string\": \"JR Yost --- No Affiliation Found\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_choice = \"S Hambrusch --- Professor, Purdue University\"\n",
        "\n",
        "# map the user choice to the author\n",
        "## index 0 in case there are multiple\n",
        "chosen_author = [\n",
        "    author\n",
        "    for author in authors_info\n",
        "    if author[\"parsed_string\"] == user_choice\n",
        "][0]\n",
        "\n",
        "# Call chat to get description of the author and their institution\n",
        "paragraph_llm = load_llm(max_tokens=200, temperature=0.5)\n",
        "prompt = f\"\"\"\n",
        "        I'm interesting in learning about researchers and research institutions.\n",
        "        Tell me about {chosen_author[\"name\"]} and their research interests, which\n",
        "        I believe include: {chosen_author[\"interests\"]}. Also tell me about their\n",
        "        insitution: {chosen_author[\"affiliations\"]}.\n",
        "        \"\"\"\n",
        "paragraph = paragraph_llm.invoke(prompt)\n",
        "print(paragraph.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5n5TJiqAfO0",
        "outputId": "235d8b38-28fc-44c8-9ff1-2719598e269f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S. Hambrusch is a professor at Purdue University with research interests in computer science education and algorithms. Purdue University is a public research university located in West Lafayette, Indiana. It is known for its strong programs in engineering, technology, and computer science.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the author's affiliation\n",
        "# author_affiliation = chosen_author.get(\n",
        "#     \"affiliations\", \"No Affiliation Found\"\n",
        "# )\n",
        "author_affiliation = \"Fribourg University\"\n",
        "\n",
        "universities_data, institution = fetch_admissions_state_data(author_affiliation)\n",
        "if universities_data:\n",
        "  print(\"The 3 universities with the highest similarity are: \")\n",
        "  print(universities_data['INSTNM'])\n",
        "else:\n",
        "  print(institution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHkHCjJOCqL-",
        "outputId": "9af954f1-4a63-4753-e3f1-6dd78817fe17"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The extracted state is: 'N/A'\n",
            "WARNING: We currently don't support international universities. We are unable to fetch statistics at this time.\n",
            "Fribourg University\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K505qaMkBaaI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}